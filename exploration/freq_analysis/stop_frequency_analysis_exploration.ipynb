{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous exploration of the GTFS data, here's where we arrived.\n",
    "\n",
    "The useful files:\n",
    "* calendar_dates.txt\n",
    "* shapes.txt\n",
    "* stop_times.txt\n",
    "* stops.txt\n",
    "* trips.txt\n",
    "    \n",
    "The Plan:\n",
    "1. Pick a date of service from calendar_dates.txt\n",
    "2. For each of the service codes (only S, U, W) on that date, collect the trip ids used (across all routes).\n",
    "3. For each trip id on each date, for each stop within each trip id, collected the scheduled stop info.\n",
    "4. Export the data:\n",
    "    * How? Ridership is organized by date, route, service key, stop. We need something that plays well with that.\n",
    "Here we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Point to where the GTFS archive data is stored.\n",
    "GTFS_ARCHIVE_PARENT_DIR = Path().home() / \"Documents\" / \"Hack Oregon\" / \"GTFS_archive_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** BEGIN ******\n",
      "Folder: trimet_20081029_0640\n",
      "\tDate: 20081012\t Service ID: U\n",
      "\tDate: 20081013\t Service ID: W\n",
      "\t\tEXPORT: /Users/jbeyer/Documents/Hack Oregon/GTFS_archive_data/trimet_20081029_0640/trimet_20081029_0640.json\n",
      "****** COMPLETE ******\n"
     ]
    }
   ],
   "source": [
    "# Loop over each archived dir. This takes a while.\n",
    "print(\"****** BEGIN ******\")\n",
    "for ARCHIVE_DIR in GTFS_ARCHIVE_PARENT_DIR.iterdir():\n",
    "    # Ignore any hidden dirs.\n",
    "    if ARCHIVE_DIR.name.startswith('.'):\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Folder: {ARCHIVE_DIR.name}\")\n",
    "\n",
    "    # Load in the files that we want.\n",
    "    # calendar_dates.txt\n",
    "    try:\n",
    "        file = 'calendar_dates.txt'\n",
    "        dates_df = pd.read_csv(ARCHIVE_DIR / file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\tUnable to locate '{file}' in {ARCHIVE_DIR}.\")\n",
    "\n",
    "    # stop_times.txt\n",
    "    try:\n",
    "        file = 'stop_times.txt'\n",
    "        times_df = pd.read_csv(ARCHIVE_DIR / file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\tUnable to locate '{file}' in {ARCHIVE_DIR}.\")\n",
    "\n",
    "    # trips.txt\n",
    "    try:\n",
    "        file = 'trips.txt'\n",
    "        trips_df = pd.read_csv(ARCHIVE_DIR / file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\tUnable to locate '{file}' in {ARCHIVE_DIR}.\")\n",
    "\n",
    "    # Init the dict to store all the stop info.\n",
    "    stops_by_time = {}\n",
    "    count = 0\n",
    "    # Look at each date - service_id combo.\n",
    "    for name, group in dates_df.groupby(['date', 'service_id']):\n",
    "        # Skip non S, U, W service ids.\n",
    "        if name[1] not in ['S', 'U', 'W']:\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"\\tDate: {name[0]}\\t Service ID: {name[1]}\")\n",
    "\n",
    "        # Find the trips and routes associated with that service on that date.\n",
    "        trips = trips_df['trip_id'][trips_df['service_id'] == name[1]]\n",
    "\n",
    "        # Look at each trip (i = index, r = row in the trips for this service id)\n",
    "        for i, r in trips_df[['route_id', 'trip_id']][trips_df['service_id'] == name[1]].iterrows():\n",
    "            # df of the stops associated with this trip\n",
    "            stops = times_df[times_df['trip_id'] == r['trip_id']]\n",
    "\n",
    "            # Look at each stop in the trip to assemble a dict of the stop times (as strings).\n",
    "            for ind, row in stops.iterrows():\n",
    "                # If that stop_id exists as a key in the dict.\n",
    "                if stops_by_time.get(str(row['stop_id']), False):\n",
    "                    # If that route exists as a key for the stop.\n",
    "                    if stops_by_time[str(row['stop_id'])].get(str(r['route_id']), False):\n",
    "                        # If that date exists as a key for the stop.\n",
    "                        if stops_by_time[str(row['stop_id'])][str(r['route_id'])].get(str(name[0]), False):\n",
    "                            # Add the stop time.\n",
    "                            stops_by_time[str(row['stop_id'])][str(r['route_id'])][str(name[0])].append(row['arrival_time'])\n",
    "                        else:\n",
    "                            # Init the date as a list and add the stop time.\n",
    "                            stops_by_time[str(row['stop_id'])][str(r['route_id'])][str(name[0])] = []\n",
    "                            stops_by_time[str(row['stop_id'])][str(r['route_id'])][str(name[0])].append(row['arrival_time'])\n",
    "                    else:\n",
    "                        # Init that route as a dict, init the date as a list, and add the stop time.\n",
    "                        stops_by_time[str(row['stop_id'])][str(r['route_id'])] = {}\n",
    "                        stops_by_time[str(row['stop_id'])][str(r['route_id'])][str(name[0])] = []\n",
    "                        stops_by_time[str(row['stop_id'])][str(r['route_id'])][str(name[0])].append(row['arrival_time'])\n",
    "                # Else init that stop as a dict, init the route as a dict, init the date as a list, and add the stop time.\n",
    "                else:\n",
    "                    stops_by_time[str(row['stop_id'])] = {}\n",
    "                    stops_by_time[str(row['stop_id'])][str(r['route_id'])] = {}\n",
    "                    stops_by_time[str(row['stop_id'])][str(r['route_id'])][str(name[0])] = []\n",
    "                    stops_by_time[str(row['stop_id'])][str(r['route_id'])][str(name[0])].append(row['arrival_time'])\n",
    "        count +=1\n",
    "        if count >= 1:\n",
    "            break\n",
    "\n",
    "    # Write to a json for further analysis.\n",
    "    EXPORT_PATH = ARCHIVE_DIR / f'{ARCHIVE_DIR.name}.json'\n",
    "    print(f'\\t\\tEXPORT: {EXPORT_PATH.name}')\n",
    "    with open(EXPORT_PATH, 'w') as fobj:\n",
    "        json.dump(stops_by_time, fobj, indent=4)\n",
    "    break\n",
    "print(\"****** COMPLETE ******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** BEGIN ******\n",
      "Folder: trimet_20081029_0640\n",
      "\tDate: 20081012\t Service ID: U\n",
      "\t\tEXPORT: trimet_20081029_0640.json\n",
      "****** COMPLETE ******\n"
     ]
    }
   ],
   "source": [
    "# Loop over each archived dir. This takes a while.\n",
    "print(\"****** BEGIN ******\")\n",
    "for ARCHIVE_DIR in GTFS_ARCHIVE_PARENT_DIR.iterdir():\n",
    "    # Ignore any hidden dirs.\n",
    "    if ARCHIVE_DIR.name.startswith('.'):\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Folder: {ARCHIVE_DIR.name}\")\n",
    "\n",
    "    # Load in the files that we want.\n",
    "    # calendar_dates.txt\n",
    "    try:\n",
    "        file = 'calendar_dates.txt'\n",
    "        dates_df = pd.read_csv(ARCHIVE_DIR / file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\tUnable to locate '{file}' in {ARCHIVE_DIR}.\")\n",
    "\n",
    "    # stop_times.txt\n",
    "    try:\n",
    "        file = 'stop_times.txt'\n",
    "        times_df = pd.read_csv(ARCHIVE_DIR / file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\tUnable to locate '{file}' in {ARCHIVE_DIR}.\")\n",
    "\n",
    "    # trips.txt\n",
    "    try:\n",
    "        file = 'trips.txt'\n",
    "        trips_df = pd.read_csv(ARCHIVE_DIR / file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\tUnable to locate '{file}' in {ARCHIVE_DIR}.\")\n",
    "\n",
    "    # Init the dict to store all the stop info.\n",
    "    stops_by_time = {}\n",
    "    count = 0\n",
    "    # Look at each date - service_id combo.\n",
    "    for name, group in dates_df.groupby(['date', 'service_id']):\n",
    "        # Skip non S, U, W service ids.\n",
    "        if name[1] not in ['S', 'U', 'W']:\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"\\tDate: {name[0]}\\t Service ID: {name[1]}\")\n",
    "            date_serv_id = '-'.join([str(name[0]), str(name[1])])\n",
    "\n",
    "        # Find the trips and routes associated with that service on that date.\n",
    "        trips = trips_df['trip_id'][trips_df['service_id'] == name[1]]\n",
    "\n",
    "        # Look at each trip (i = index, r = row in the trips for this service id)\n",
    "        for i, r in trips_df[['route_id', 'trip_id']][trips_df['service_id'] == name[1]].iterrows():\n",
    "            # df of the stops associated with this trip\n",
    "            stops = times_df[times_df['trip_id'] == r['trip_id']]\n",
    "\n",
    "            # Look at each stop in the trip to assemble a dict of the stop times (as strings).\n",
    "            for ind, row in stops.iterrows():\n",
    "                # If that route exists as a key in the dict.\n",
    "                if stops_by_time.get(str(r['route_id']), False):\n",
    "                    # If that stop exists as a key for the route.\n",
    "                    if stops_by_time[str(r['route_id'])].get(str(row['stop_id']), False):\n",
    "                        # If that date exists as a key for the stop.\n",
    "                        if stops_by_time[str(r['route_id'])][str(row['stop_id'])].get(date_serv_id, False):\n",
    "                            # Add the stop time.\n",
    "                            stops_by_time[str(r['route_id'])][str(row['stop_id'])][date_serv_id].append(row['arrival_time'])\n",
    "                        else:\n",
    "                            # Init the date as a list and add the stop time.\n",
    "                            stops_by_time[str(r['route_id'])][str(row['stop_id'])][date_serv_id] = []\n",
    "                            stops_by_time[str(r['route_id'])][str(row['stop_id'])][date_serv_id].append(row['arrival_time'])\n",
    "                    else:\n",
    "                        # Init that route as a dict, init the date as a list, and add the stop time.\n",
    "                        stops_by_time[str(r['route_id'])][str(row['stop_id'])] = {}\n",
    "                        stops_by_time[str(r['route_id'])][str(row['stop_id'])][date_serv_id] = []\n",
    "                        stops_by_time[str(r['route_id'])][str(row['stop_id'])][date_serv_id].append(row['arrival_time'])\n",
    "                # Else init that stop as a dict, init the route as a dict, init the date as a list, and add the stop time.\n",
    "                else:\n",
    "                    stops_by_time[str(r['route_id'])] = {}\n",
    "                    stops_by_time[str(r['route_id'])][str(row['stop_id'])] = {}\n",
    "                    stops_by_time[str(r['route_id'])][str(row['stop_id'])][date_serv_id] = []\n",
    "                    stops_by_time[str(r['route_id'])][str(row['stop_id'])][date_serv_id].append(row['arrival_time'])\n",
    "        count +=1\n",
    "        if count >= 1:\n",
    "            break\n",
    "\n",
    "    # Write to a json for further analysis.\n",
    "    EXPORT_PATH = ARCHIVE_DIR / f'{ARCHIVE_DIR.name}.json'\n",
    "    print(f'\\t\\tEXPORT: {EXPORT_PATH.name}')\n",
    "    with open(EXPORT_PATH, 'w') as fobj:\n",
    "        json.dump(stops_by_time, fobj, indent=4)\n",
    "    break\n",
    "print(\"****** COMPLETE ******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
