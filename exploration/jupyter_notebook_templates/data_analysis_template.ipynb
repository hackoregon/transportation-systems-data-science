{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Jupyter Notebook Templates - ODOT Crash Data\n",
    "* [Locally Running Postgres Server](#Local-Postgres-Sever)\n",
    "* [Locally Running API](#Local-API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Postgres Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the ODOT crash data through a local copy of the Postgres database.\n",
    "* Make sure you have the Docker container set up and running (instructions [here](https://github.com/hackoregon/transportation-system-backend)).\n",
    "\n",
    "* Import the `psycopg2` Postgres adaptor for python (can be installed with `pip` or `conda`).\n",
    "\n",
    "```python\n",
    "import psycopg2\n",
    "```\n",
    "\n",
    "* Use the Pandas data analysis library to handle the database data.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "```\n",
    "\n",
    "\n",
    "* Create a connection object `conn` to the database using the listed arguments. Of important note is matching `dbname` to the one you're looking for, and that the `port` # is correct (I believe it is defined by the Docker container. Make sure to use the `password` you set in the .env file when setting up the database).\n",
    "\n",
    "```python\n",
    "conn = psycopg2.connect(host='localhost',\n",
    "                        dbname='odot_crash_data',\n",
    "                        user='postgres',\n",
    "                        port='5439',\n",
    "                        password='<sUpEr.SeCrEt.PaSsWoRD>')\n",
    "```\n",
    "\n",
    "* For a little information about the database, we can get a list of the table names from the schema using a `curs` object.\n",
    "\n",
    "```python\n",
    "curs.execute(\"\"\"SELECT table_name FROM information_schema.tables WHERE table_schema='public'\"\"\")\n",
    "tables = [x[0] for x in curs.fetchall()]\n",
    "print(tables)\n",
    "```\n",
    "\n",
    "* Currently, we've identified the \"crash\", \"vhcl\" and \"partic\" tables as the ones to begin with. However, there are additional tables available that are NOT yet enabled in the API. To make a DataFrame out of one of them, in this case the \"crash\" database, use the `pd.read_sql()` method. This usage pulls the full table into a pandas DataFrame.\n",
    "\n",
    "```python\n",
    "dataframe = pd.read_sql(\"SELECT * FROM crash\", conn)\n",
    "```\n",
    "\n",
    "* After just a second, the DataFrame should be populated. To view the first couple of rows, use the `.head()` method.\n",
    "\n",
    "```python\n",
    "dataframe.head()\n",
    "```\n",
    "\n",
    "Now you have a pandas DataFrame full with your odot crash data using a locally run copy of the Postgres database!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "conn = psycopg2.connect(host='localhost', dbname='odot_crash_data', user='postgres', port='5439', password='')\n",
    "curs = conn.cursor()\n",
    "curs.execute(\"\"\"SELECT table_name FROM information_schema.tables WHERE table_schema='public'\"\"\")\n",
    "tables = [_[0] for _ in curs.fetchall()]\n",
    "print(tables)\n",
    "dataframe = pd.read_sql(\"SELECT * FROM crash\", conn)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the ODOT crash data through a local copy of the API.\n",
    "\n",
    "* Make sure you have the Docker container set up and running (instructions [here](https://github.com/hackoregon/transportation-system-backend)).\n",
    "\n",
    "* Import the `requests` library to make the API calls.\n",
    "\n",
    "```python\n",
    "import requests\n",
    "```\n",
    "\n",
    "* Use the Pandas data analysis library to handle the database data.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "```\n",
    "\n",
    "\n",
    "* First make a call to the base api. That will give schema information.\n",
    "\n",
    "```python\n",
    "response = requests.get('http://localhost:8000/api/')\n",
    "for key in response.json().keys()\n",
    "    print(key)\n",
    "```\n",
    "\n",
    "* To access a specific table from that list, enter it into the next field in the URL. In this call, we'll see how many records are in the \"crashes\" table. This can be found in the 'count' field of the json response object. If you were curious, the other fields available in addition to 'count' are 'next', 'previous', and 'results'. The 'next' and 'previous' fields are used to access the pagination.\n",
    "\n",
    "```python\n",
    "response = requests.get('http://localhost:8000/api/crashes/')\n",
    "num_records = response.json()['count']\n",
    "```\n",
    "\n",
    "* Anyway, now that we have the record count, we can pull the full database at once (rather than paginate) by passing `num_records` as the 'limit' parameter in our query. If no 'limit' parameter is passed, the default pagination returns 10 records. Note: This makes use of Python f-strings, which came about in Python 3.6.\n",
    "\n",
    "```python\n",
    "response = requests.get(f\"http://localhost:8000/api/crashes/?limit={num_records}\")\n",
    "```\n",
    "\n",
    "* This call may take some time (for all the records), but after it returns you can create a DataFrame directly from the 'results' field of the json response object. \n",
    "\n",
    "```python\n",
    "df_crash = pd.DataFrame(response.json()['results'])\n",
    "```\n",
    "\n",
    "* To view the first couple of rows of the data, use the `.head()` method.\n",
    "\n",
    "```python\n",
    "dataframe.head()\n",
    "```\n",
    "\n",
    "* Finally, you may was to set the `crash_id` field as the index of the DataFrame. To do so:\n",
    "\n",
    "```python\n",
    "df_crash.set_index('crash_id', drop=True, inplace=True)\n",
    "```\n",
    "\n",
    "Now you have a pandas DataFrame full with your odot crash data using a locally run copy of the API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "# Get API schema.\n",
    "response = requests.get('http://localhost:8000/api/')\n",
    "for key in response.json().keys():\n",
    "    print(key)\n",
    "# Get the 'crashes' table record count.\n",
    "response = requests.get('http://localhost:8000/api/crashes/')\n",
    "num_records = response.json()['count']\n",
    "# Pull all the records from the 'crashes' table.\n",
    "response = requests.get(f\"http://localhost:8000/api/crashes/?limit={num_records}\")\n",
    "dataframe = pd.DataFrame(response.json()['results'])\n",
    "dataframe.set_index('crash_id', drop=True, inplace=True)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
